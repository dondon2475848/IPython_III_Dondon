{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import json\n",
    "\n",
    "\n",
    "model = gensim.models.Doc2Vec.load('./data/Doc2Vec_Size_100_1_m_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "魯肉飯 0.921170175076\n",
      "肉燥飯 0.860764622688\n",
      "控肉飯 0.824838399887\n",
      "麵線 0.808075010777\n",
      "雞肉飯 0.807068169117\n",
      "乾麵 0.798507988453\n",
      "豬油拌飯 0.788621544838\n",
      "油飯 0.769047021866\n",
      "肉羹湯 0.761376202106\n",
      "排骨飯 0.760819017887\n"
     ]
    }
   ],
   "source": [
    "# 相似度\n",
    "for ele in model.most_similar(u'滷肉飯', topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56079d212756dd184f282124 0.756299674511\n",
      "56cb0ade699b6e0737c94c6b 0.756243109703\n",
      "54c4a1d62756dd7ce9f38d3d 0.733508527279\n",
      "54a172bcd4fdab219233e7fe 0.711138665676\n",
      "53bdcbdfd4fdab09ca3909e3 0.709210574627\n"
     ]
    }
   ],
   "source": [
    "#作者相似度\n",
    "for ele in model.docvecs.most_similar([\"557bca87699b6e6e88553d8e\"], topn = 5):\n",
    "        print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蔬菜水果 0.579964160919\n",
      "魚料 0.553462982178\n",
      "生菜 0.549664080143\n",
      "肉類 0.54927700758\n",
      "肉品 0.538128256798\n",
      "肉片 0.533275485039\n",
      "魚生 0.533119559288\n",
      "蔬果 0.531435668468\n",
      "生魚片 0.522937238216\n",
      "食材 0.516968011856\n"
     ]
    }
   ],
   "source": [
    "for ele in model.most_similar(positive=[u'蔬菜'], negative=[u'菇'], topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "雞排 0.630074322224\n",
      "Pizza 0.616584599018\n",
      "熱狗堡 0.615270376205\n",
      "豬排 0.606273591518\n",
      "潛艇堡 0.606119453907\n",
      "甜甜圈 0.593104064465\n",
      "雞腿堡 0.589587569237\n",
      "鬆餅 0.58511865139\n",
      "美式漢堡 0.583975553513\n",
      "牛排 0.578551292419\n"
     ]
    }
   ],
   "source": [
    "for ele in model.most_similar(positive=[u'炸雞',u'漢堡'], negative=[u'青菜'], topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蔬果 0.86394816637\n",
      "菇類 0.857580423355\n",
      "青菜 0.821973264217\n",
      "蔬菜水果 0.782311081886\n",
      "各式蔬菜 0.77644443512\n",
      "生菜 0.774259567261\n",
      "蔬菜類 0.729254841805\n",
      "海鮮 0.724322378635\n",
      "青蔬 0.722296774387\n",
      "鮮蔬 0.719903290272\n"
     ]
    }
   ],
   "source": [
    "for ele in model.most_similar([u'蔬菜'],topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583282\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "# KMean前處理\n",
    "# 詞清單\n",
    "wordlist = model.index2word\n",
    "# 詞向量\n",
    "wordVector = model.syn0\n",
    "wordVectorShape=wordVector.shape[0]\n",
    "print  wordVectorShape\n",
    "num_clusters = wordVectorShape/ 2000\n",
    "print num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "\n",
    "\n",
    "word_vectors = model.syn0\n",
    "#num_clusters = 200\n",
    "num_clusters = wordVectorShape/ 2000\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\"\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the first 10 clusters\n",
    "for cluster in xrange(0,10):\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/doc2Vec_KMeans200.json','w') as f:\n",
    "    json.dump(word_centroid_map,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "stratTime=time.time()\n",
    "for cluster in xrange(0,2):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #l.syn0\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])    \n",
    "    print json.dumps(words,ensure_ascii=False).encode('utf-8') \n",
    "EndTime = time.time()\n",
    "CostTime = EndTime - stratTime\n",
    "print '總共花了',CostTime,'秒'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
