{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#coding=utf-8\n",
    "#import\n",
    "import gensim\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "主題詞字典的長度 72838\n"
     ]
    }
   ],
   "source": [
    "with open('./data/subject.json' , 'r') as f:\n",
    "    subjectDic = json.load(f)\n",
    "print '主題詞字典的長度',len(subjectDic)\n",
    "model = gensim.models.Word2Vec.load('./data/Word2Vec_sz_200_mc_1_sg_by_sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Def\n",
    "def PrintKeyValue(dic_in):\n",
    "    for key, value in dic_in.iteritems() :\n",
    "        print key,'  :  ', value\n",
    "def jsonDump(dataIn):\n",
    "    print json.dumps(dataIn,ensure_ascii=False).encode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 抓主題詞測試程式碼"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"negativeSubject\": [[\"米心\", \"偏硬\"], [\"用量\", \"偏酸\"], [\"香濃\", \"醇厚\"], [\"遜色\", \"香濃\"]], \"author_id\": \"54ddafec2756dd76b8e10cd5\", \"score\": 105, \"positiveSubject\": [[\"台灣\", \"空間\"], [\"南歐\", \"道地\"], [\"佳餚\", \"健康\"], [\"製作\", \"美味\"], [\"烤蒜頭\", \"甜味\"], [\"沒有\", \"咬勁\"], [\"瘦肉\", \"特別\"], [\"藝術品\", \"美食\"], [\"圖案\", \"美麗\"], [\"甜菜根\", \"有質感\"], [\"nt600\", \"精緻\"], [\"感官\", \"銷魂\"], [\"麵包\", \"意猶未盡\"], [\"香味\", \"美妙\"], [\"著蝦\", \"香味\"], [\"上欖\", \"很棒\"], [\"表面\", \"口感\"], [\"口感\", \"外酥內軟\"], [\"軟法\", \"不膩口\"], [\"橄油\", \"濕潤\"], [\"西班牙\", \"香氣四溢\"], [\"滋味\", \"多層次\"], [\"辣味\", \"滋味\"], [\"中和\", \"甜味\"], [\"味道\", \"口感\"], [\"天使\", \"驚喜\"], [\"麵食\", \"有特色\"], [\"肋排\", \"香\"], [\"醬汁\", \"咬勁\"], [\"香米\", \"口感\"], [\"義大利\", \"口感\"], [\"米粒\", \"香\"], [\"大蒜\", \"濕潤\"], [\"蔬菜\", \"新奇\"], [\"令人\", \"滋味\"], [\"堅果\", \"香脆\"], [\"果乾\", \"柔軟\"], [\"菠菜\", \"特別\"], [\"熱菜\", \"豐富\"], [\"莎莎醬\", \"滋味\"], [\"加點\", \"開胃\"], [\"糯米\", \"停不下來\"], [\"甜味\", \"滋味\"], [\"地瓜\", \"甜美\"], [\"零嘴\", \"香脆\"], [\"番薯\", \"開胃\"], [\"下酒菜\", \"喜歡\"], [\"風味\", \"品嚐\"], [\"微酸\", \"酒香\"], [\"酒香\", \"香氣\"], [\"沙拉\", \"甘甜\"], [\"甘甜\", \"新鮮\"], [\"新鮮\", \"沒話說\"], [\"海鮮總匯\", \"奢華\"], [\"奇異果\", \"自然\"], [\"偏酸\", \"很實在\"], [\"質地\", \"濃稠\"], [\"nt150\", \"不貴\"], [\"果汁\", \"滋味\"], [\"優格\", \"健康\"], [\"tapas\", \"酒香\"], [\"貝里思\", \"雅致\"], [\"咖啡\", \"香\"], [\"貝里詩\", \"酒香\"], [\"奶泡\", \"綿密\"], [\"綿密\", \"划算\"], [\"酒類\", \"健康\"], [\"伊比利豬\", \"稀有\"], [\"法國\", \"美食\"], [\"老闆\", \"道地\"], [\"壓力感\", \"空間\"], [\"座位\", \"特別\"], [\"工業\", \"浪漫\"], [\"微醺\", \"氛圍\"], [\"壓力\", \"悠閒\"], [\"寧靜\", \"美食\"]], \"_id\": \"56700c555c371f3e053870fc\"}\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(subjectDic.values()[3],ensure_ascii=False).encode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"台灣\", \"南歐\", \"佳餚\", \"製作\", \"烤蒜頭\", \"沒有\", \"瘦肉\", \"藝術品\", \"圖案\", \"甜菜根\", \"nt600\", \"感官\", \"麵包\", \"香味\", \"著蝦\", \"上欖\", \"表面\", \"口感\", \"軟法\", \"橄油\", \"西班牙\", \"滋味\", \"辣味\", \"中和\", \"味道\", \"天使\", \"麵食\", \"肋排\", \"醬汁\", \"香米\", \"義大利\", \"米粒\", \"大蒜\", \"蔬菜\", \"令人\", \"堅果\", \"果乾\", \"菠菜\", \"熱菜\", \"莎莎醬\", \"加點\", \"糯米\", \"甜味\", \"地瓜\", \"零嘴\", \"番薯\", \"下酒菜\", \"風味\", \"微酸\", \"酒香\", \"沙拉\", \"甘甜\", \"新鮮\", \"海鮮總匯\", \"奇異果\", \"偏酸\", \"質地\", \"nt150\", \"果汁\", \"優格\", \"tapas\", \"貝里思\", \"咖啡\", \"貝里詩\", \"奶泡\", \"綿密\", \"酒類\", \"伊比利豬\", \"法國\", \"老闆\", \"壓力感\", \"座位\", \"工業\", \"微醺\", \"壓力\", \"寧靜\", \"米心\", \"用量\", \"香濃\", \"遜色\"]\n"
     ]
    }
   ],
   "source": [
    "subjectList = []\n",
    "for dic in subjectDic.values()[3:4]:\n",
    "    for list1 in dic['positiveSubject']:\n",
    "        if list1[0] not in subjectList:\n",
    "            subjectList.append(list1[0])\n",
    "    for list2 in dic['negativeSubject']:\n",
    "        if list2[0] not in subjectList:\n",
    "            subjectList.append(list2[0])\n",
    "\n",
    "            \n",
    "jsonDump(subjectList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 存取抓取的主題詞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjectList的長度為： 83630\n",
      "共花了 1117.51546884 秒\n"
     ]
    }
   ],
   "source": [
    "startTime=time.time()\n",
    "subjectList = []\n",
    "for dic in subjectDic.values():\n",
    "    for list1 in dic['positiveSubject']:\n",
    "        if list1[0] not in subjectList:\n",
    "            subjectList.append(list1[0])\n",
    "    for list2 in dic['negativeSubject']:\n",
    "        if list2[0] not in subjectList:\n",
    "            subjectList.append(list2[0])\n",
    "            \n",
    "#jsonDump(subjectList)\n",
    "print 'subjectList的長度為：',len(subjectList)\n",
    "with open('./data/subjectList.json','w') as f:\n",
    "    json.dump(subjectList,f)\n",
    "endTime=time.time()\n",
    "print '共花了',endTime-startTime,'秒'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjectList的長度為： 83630\n"
     ]
    }
   ],
   "source": [
    "print 'subjectList的長度為：',len(subjectList)\n",
    "with open('./data/subjectList.json','w') as f:\n",
    "    json.dump(subjectList,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subjectList的長度為： 83630\n"
     ]
    }
   ],
   "source": [
    "with open('./data/subjectList.json','r') as f:\n",
    "    subjectList = json.load(f)\n",
    "print 'subjectList的長度為：',len(subjectList)  \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "584926\n",
      "<type 'list'>\n",
      "的\n",
      "是\n",
      "了\n",
      "-\n",
      "、\n",
      "有\n",
      "也\n",
      "吃\n",
      "我\n",
      "很\n"
     ]
    }
   ],
   "source": [
    "# KMean前處理\n",
    "# 詞清單\n",
    "wordList = model.index2word\n",
    "print len(wordList)\n",
    "print type(wordList)\n",
    "\n",
    "for word in wordList[0:10]:\n",
    "    print word\n",
    "    if word in subjectList:\n",
    "        print word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "魯肉飯 0.920013606548\n",
      "肉燥飯 0.817839920521\n",
      "控肉飯 0.771877467632\n",
      "豬腳飯 0.767785131931\n",
      "肉羹麵 0.761341094971\n",
      "魯肉 0.76116591692\n",
      "鼎邊銼 0.750468194485\n",
      "焢肉飯 0.735240876675\n",
      "筒仔米糕 0.734119534492\n",
      "焢肉 0.731191277504\n"
     ]
    }
   ],
   "source": [
    "# 相似度\n",
    "for ele in model.most_similar(u'滷肉飯', topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398925\n",
      "79785\n"
     ]
    }
   ],
   "source": [
    "# KMean前處理\n",
    "# 詞清單\n",
    "wordlist = model.index2word\n",
    "# 詞向量\n",
    "wordVector = model.syn0\n",
    "wordVectorShape=wordVector.shape[0]\n",
    "print  wordVectorShape\n",
    "num_clusters = wordVectorShape/ 5\n",
    "print num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "398925\n",
      "[\"是\", \"了\", \"有\", \"我\", \"吃\", \"就\", \"在\", \"很\", \"也\", \"來\", \"這\", \"但\", \"和\", \"都\", \"可以\", \"到\", \"我們\", \"就是\", \"元\"]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "<type 'numpy.ndarray'>\n",
      "398925\n",
      "[ 0.28682771 -0.07586922  0.1578736   0.11840189  0.16901097 -0.09892504\n",
      "  0.03410177  0.00984159  0.29855445 -0.12518986  0.09773253  0.1572655\n",
      " -0.13239793  0.04892337 -0.13496728  0.4081839   0.3338187  -0.03503511\n",
      "  0.11309864 -0.17892414 -0.08576016  0.25438815  0.15055723 -0.05878566\n",
      "  0.24155891  0.26643324  0.14156783  0.30228481  0.12343887  0.35488629\n",
      " -0.06419866 -0.09948944  0.14322282  0.34893551  0.25273603  0.09931388\n",
      "  0.18456919  0.10962344 -0.12785533  0.07407416 -0.00332142  0.13633065\n",
      "  0.1573704  -0.05271621  0.0078309  -0.2508778  -0.16921134 -0.08169635\n",
      "  0.13334352 -0.29259396  0.19113475  0.00621219  0.16497807 -0.07298919\n",
      "  0.10587206 -0.33191103 -0.07477511  0.57821494  0.08147391  0.26024202\n",
      "  0.23402673 -0.14885977 -0.28057665  0.40553451 -0.01835755 -0.13782953\n",
      " -0.26745373 -0.02163964  0.09326798 -0.11839873  0.1250513   0.15364447\n",
      " -0.15924311 -0.26229358  0.02645428  0.07715113  0.01917546  0.20793523\n",
      " -0.08626562  0.09993894 -0.2239581   0.13592109 -0.06057491 -0.06443176\n",
      "  0.27240378 -0.18329249  0.4510695  -0.06763237 -0.14515606 -0.04874828\n",
      "  0.0286699   0.2640416  -0.5431062  -0.11236562 -0.07460453  0.03569164\n",
      " -0.1268836   0.05823161 -0.31280532  0.00221073  0.01411399 -0.02537353\n",
      "  0.40009019  0.00378704 -0.03304126 -0.20185323  0.1105138  -0.01465711\n",
      " -0.16640317  0.09354633 -0.07187788 -0.18450265  0.03515282 -0.27079362\n",
      " -0.20727046 -0.33027261  0.1789612   0.00520772  0.18822801  0.24613748\n",
      "  0.24988817  0.11904282 -0.10586867  0.36883339  0.25849795  0.02946899\n",
      "  0.16533497  0.17744717 -0.05758619 -0.03234879 -0.05991562 -0.28725687\n",
      " -0.23538472 -0.13862531 -0.05659291  0.03167556  0.1356023   0.31296074\n",
      "  0.16451468  0.00747784 -0.00839395  0.53334004  0.02459663 -0.13654786\n",
      " -0.06253088  0.08923489  0.09565641 -0.12996809 -0.1777256   0.21203466\n",
      "  0.15009262 -0.27477816  0.16972835 -0.01310953  0.12676138  0.11942206\n",
      " -0.16907871  0.00880168  0.33973509 -0.66658527 -0.03566511 -0.04799718\n",
      "  0.14860703 -0.43798599 -0.01083567 -0.07447539  0.18993063  0.21413919\n",
      " -0.28010496 -0.16859859  0.2099378   0.14688455  0.10839351  0.00739631\n",
      "  0.09745569  0.648045    0.02335686  0.06190505 -0.03708335  0.23432423\n",
      "  0.25553542  0.05490432 -0.18994077 -0.00073832 -0.05615102  0.29661077\n",
      "  0.16849719 -0.31278843  0.06667123 -0.13669346  0.32461685  0.09295267\n",
      " -0.22703646  0.13133678  0.31731579 -0.11638959 -0.00421851  0.06002282\n",
      "  0.04536716 -0.34953755]\n",
      "200\n",
      "2\n",
      "(398925, 200)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print  type(wordlist)\n",
    "print len(wordlist)\n",
    "print json.dumps(wordlist[1:20],ensure_ascii=False).encode('utf-8')\n",
    "print '------------------------------------------------------------------------------------------------------'\n",
    "print  type(wordVector)\n",
    "print len(wordVector)\n",
    "print(wordVector[0])\n",
    "print len(wordVector[0])\n",
    "\n",
    "print(wordVector.ndim)\n",
    "print(wordVector.shape)\n",
    "print(wordVector.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[Spectral Clustering \\xe5\\x89\\x8d\\xe8\\x99\\x95\\xe7\\x90\\x86]\\n\\nimport numpy as np\\n\\n\\xe5\\x85\\xa8\\xe9\\x83\\xa8\\xe8\\xa9\\x9e\\xe7\\xae\\x97\\xe7\\x9b\\xb8\\xe4\\xbc\\xbc\\xe5\\xba\\xa6\\n\\nsmatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(model.syn0.T))\\nnsarray = np.array(smatrix) <=== \\xe6\\x9c\\x83\\xe7\\x95\\xb6\\xe6\\xa9\\x9f\\n\\n\\xe8\\x8b\\xa5\\xe5\\xb7\\xb2\\xe7\\xb6\\x93\\xe6\\x8a\\x8a\\xe8\\xa9\\x9e\\xe7\\x9a\\x84\\xe7\\xaf\\x84\\xe5\\x9c\\x8d\\xe7\\xb8\\xae\\xe6\\xb8\\x9b\\xef\\xbc\\x8c\\xe5\\x89\\x87\\xe5\\x8f\\xaf\\xe7\\x94\\xa8\\xe4\\xb8\\x8b\\xe9\\x9d\\xa2\\xe9\\x80\\x99\\xe5\\x80\\x8b\\xe6\\x96\\xb9\\xe5\\xbc\\x8f\\n\\xe6\\xaf\\x8f\\xe5\\x80\\x8b\\xe8\\xa9\\x9e\\xe7\\x9a\\x84\\xe5\\x90\\x91\\xe9\\x87\\x8f\\xe9\\x95\\xb7\\xe5\\xba\\xa6\\xe6\\x98\\xafn\\xef\\xbc\\x8c\\xe8\\xa8\\x93\\xe7\\xb7\\xb4\\xe6\\x99\\x82\\xe6\\x88\\x91\\xe6\\x98\\xaf\\xe5\\xb0\\x87n\\xe8\\xa8\\xad\\xe7\\x82\\xba200\\n\\xe6\\x8e\\xa5\\xe8\\x91\\x97\\xe6\\x8a\\x8a\\xe8\\xa9\\x9e\\xe5\\x90\\x91\\xe9\\x87\\x8f\\xe6\\x94\\xbe\\xe5\\x85\\xa5list\\n\\nwordVectorList = [wordvector1,wordvector2,...,...]\\nnsmatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(np.array(wordVectorList).T))\\n\\n\\xe7\\xae\\x97\\xe5\\x87\\xba\\xe4\\xbe\\x86\\xe7\\x9a\\x84\\xe7\\x9b\\xb8\\xe4\\xbc\\xbc\\xe5\\xba\\xa6\\xe5\\x9b\\xa0\\xe7\\x82\\xba\\xe6\\x98\\xaf\\xe6\\xb5\\xae\\xe9\\xbb\\x9e\\xe6\\x95\\xb8\\xef\\xbc\\x8c\\xe6\\x9c\\x83\\xe6\\x9c\\x89>1\\xe6\\x88\\x96<-1\\xe7\\x9a\\x84\\xe6\\x83\\x85\\xe6\\xb3\\x81\\xef\\xbc\\x8c\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe4\\xbf\\xae\\xe6\\xad\\xa3\\n\\nnsarray = np.array(nsmatrix)\\nnsarray[nsarray>1] = 1.0\\nnsarray[nsarray<-1] = -1.0\\n\\n\\xe5\\x8f\\xa6\\xe5\\xa4\\x96\\xe5\\x8f\\xaf\\xe4\\xbb\\xa5\\xe6\\x8a\\x8a\\xe9\\xa4\\x98\\xe5\\xbc\\xa6\\xe7\\x9b\\xb8\\xe4\\xbc\\xbc\\xe5\\xba\\xa6\\xe8\\xbd\\x89\\xe6\\x8f\\x9b\\xe7\\x82\\xba\\xe5\\xbc\\xa7\\xe5\\xba\\xa6\\xef\\xbc\\x8c\\xe5\\x86\\x8d\\xe8\\xbd\\x89\\xe6\\x8f\\x9b\\xe7\\x82\\xba\\xe4\\xbb\\x8b\\xe6\\x96\\xbc0~1\\xe4\\xb9\\x8b\\xe9\\x96\\x93\\xe7\\x9a\\x84\\xe7\\x9b\\xb8\\xe4\\xbc\\xbc\\xe5\\xba\\xa6\\n\\nangularD = np.arccos(nsarray)/math.pi\\nsim = 1 - angularD\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "[Spectral Clustering 前處理]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "全部詞算相似度\n",
    "\n",
    "smatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(model.syn0.T))\n",
    "nsarray = np.array(smatrix) <=== 會當機\n",
    "\n",
    "若已經把詞的範圍縮減，則可用下面這個方式\n",
    "每個詞的向量長度是n，訓練時我是將n設為200\n",
    "接著把詞向量放入list\n",
    "\n",
    "wordVectorList = [wordvector1,wordvector2,...,...]\n",
    "nsmatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(np.array(wordVectorList).T))\n",
    "\n",
    "算出來的相似度因為是浮點數，會有>1或<-1的情況，要再修正\n",
    "smatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(model.syn0.T))\n",
    "nsarray = np.array(smatrix) smatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(model.syn0.T))\n",
    "nsarray = np.array(smatrix) \n",
    "nsarray = np.array(nsmatrix)\n",
    "nsarray[nsarray>1] = 1.0\n",
    "nsarray[nsarray<-1] = -1.0\n",
    "\n",
    "另外可以把餘弦相似度轉換為弧度，再轉換為介於0~1之間的相似度\n",
    "\n",
    "angularD = np.arccos(nsarray)/math.pi\n",
    "sim = 1 - angularD\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-74747816a7cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# computing K-Means with K = 2 (2 clusters)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcentroids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# assign each sample to a cluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/scipy/cluster/vq.pyc\u001b[0m in \u001b[0;36mkmeans\u001b[1;34m(obs, k_or_guess, iter, thresh, check_finite)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m     \"\"\"\n\u001b[1;32m--> 539\u001b[1;33m     \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iter must be at least 1.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/scipy/_lib/_util.pyc\u001b[0m in \u001b[0;36m_asarray_validated\u001b[1;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'masked arrays are not supported'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mtoarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobjects_ok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'O'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    664\u001b[0m     \"\"\"\n\u001b[0;32m    665\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AllFloat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m         raise ValueError(\n\u001b[0;32m    668\u001b[0m             \"array must not contain infs or NaNs\")\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  1711.21886206 seconds.\n",
      "\n",
      "Cluster 0\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1120, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 301, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 346, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/inspect.py\", line 491, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[0;32m   1828\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 1830\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   1831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1394\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1302\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1303\u001b[0m             )\n\u001b[0;32m   1304\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "\n",
    "\n",
    "word_vectors = model.syn0\n",
    "num_clusters =15\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\"\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))\n",
    "\n",
    "# For the first 10 clusters\n",
    "for cluster in xrange(0,10):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
