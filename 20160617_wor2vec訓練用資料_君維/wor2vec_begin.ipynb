{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import json\n",
    "\n",
    "'''\n",
    "要自己訓練的話用這個，setence是一個list，裡面每個element則是由切好的詞構成的list\n",
    "\n",
    "\n",
    "例如：\n",
    "sentence = [['今天','實在','很熱'],['感覺','路面','可以','煎蛋']]\n",
    "\n",
    "模型參數看官方文件說明：https://radimrehurek.com/gensim/models/word2vec.html\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "model = gensim.models.Word2Vec(sentence, size=200, workers=2, min_count=1, sg=1)\n",
    "'''\n",
    "model = gensim.models.Word2Vec.load('./mymodelSG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "魯肉飯 0.893000423908\n",
      "肉燥飯 0.810384392738\n",
      "控肉飯 0.757050454617\n",
      "爌肉飯 0.754742383957\n",
      "爌肉 0.746101021767\n",
      "焢肉 0.742386460304\n",
      "滷肉 0.740453720093\n",
      "焢肉飯 0.7402151227\n",
      "肉燥 0.733509778976\n",
      "控肉 0.723708808422\n"
     ]
    }
   ],
   "source": [
    "# 相似度\n",
    "for ele in model.most_similar(u'滷肉飯', topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "398925\n",
      "79785\n"
     ]
    }
   ],
   "source": [
    "# KMean前處理\n",
    "# 詞清單\n",
    "wordlist = model.index2word\n",
    "# 詞向量\n",
    "wordVector = model.syn0\n",
    "wordVectorShape=wordVector.shape[0]\n",
    "print  wordVectorShape\n",
    "num_clusters = wordVectorShape/ 5\n",
    "print num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n",
      "398925\n",
      "[\"是\", \"了\", \"有\", \"我\", \"吃\", \"就\", \"在\", \"很\", \"也\", \"來\", \"這\", \"但\", \"和\", \"都\", \"可以\", \"到\", \"我們\", \"就是\", \"元\"]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "<type 'numpy.ndarray'>\n",
      "398925\n",
      "[ 0.28682771 -0.07586922  0.1578736   0.11840189  0.16901097 -0.09892504\n",
      "  0.03410177  0.00984159  0.29855445 -0.12518986  0.09773253  0.1572655\n",
      " -0.13239793  0.04892337 -0.13496728  0.4081839   0.3338187  -0.03503511\n",
      "  0.11309864 -0.17892414 -0.08576016  0.25438815  0.15055723 -0.05878566\n",
      "  0.24155891  0.26643324  0.14156783  0.30228481  0.12343887  0.35488629\n",
      " -0.06419866 -0.09948944  0.14322282  0.34893551  0.25273603  0.09931388\n",
      "  0.18456919  0.10962344 -0.12785533  0.07407416 -0.00332142  0.13633065\n",
      "  0.1573704  -0.05271621  0.0078309  -0.2508778  -0.16921134 -0.08169635\n",
      "  0.13334352 -0.29259396  0.19113475  0.00621219  0.16497807 -0.07298919\n",
      "  0.10587206 -0.33191103 -0.07477511  0.57821494  0.08147391  0.26024202\n",
      "  0.23402673 -0.14885977 -0.28057665  0.40553451 -0.01835755 -0.13782953\n",
      " -0.26745373 -0.02163964  0.09326798 -0.11839873  0.1250513   0.15364447\n",
      " -0.15924311 -0.26229358  0.02645428  0.07715113  0.01917546  0.20793523\n",
      " -0.08626562  0.09993894 -0.2239581   0.13592109 -0.06057491 -0.06443176\n",
      "  0.27240378 -0.18329249  0.4510695  -0.06763237 -0.14515606 -0.04874828\n",
      "  0.0286699   0.2640416  -0.5431062  -0.11236562 -0.07460453  0.03569164\n",
      " -0.1268836   0.05823161 -0.31280532  0.00221073  0.01411399 -0.02537353\n",
      "  0.40009019  0.00378704 -0.03304126 -0.20185323  0.1105138  -0.01465711\n",
      " -0.16640317  0.09354633 -0.07187788 -0.18450265  0.03515282 -0.27079362\n",
      " -0.20727046 -0.33027261  0.1789612   0.00520772  0.18822801  0.24613748\n",
      "  0.24988817  0.11904282 -0.10586867  0.36883339  0.25849795  0.02946899\n",
      "  0.16533497  0.17744717 -0.05758619 -0.03234879 -0.05991562 -0.28725687\n",
      " -0.23538472 -0.13862531 -0.05659291  0.03167556  0.1356023   0.31296074\n",
      "  0.16451468  0.00747784 -0.00839395  0.53334004  0.02459663 -0.13654786\n",
      " -0.06253088  0.08923489  0.09565641 -0.12996809 -0.1777256   0.21203466\n",
      "  0.15009262 -0.27477816  0.16972835 -0.01310953  0.12676138  0.11942206\n",
      " -0.16907871  0.00880168  0.33973509 -0.66658527 -0.03566511 -0.04799718\n",
      "  0.14860703 -0.43798599 -0.01083567 -0.07447539  0.18993063  0.21413919\n",
      " -0.28010496 -0.16859859  0.2099378   0.14688455  0.10839351  0.00739631\n",
      "  0.09745569  0.648045    0.02335686  0.06190505 -0.03708335  0.23432423\n",
      "  0.25553542  0.05490432 -0.18994077 -0.00073832 -0.05615102  0.29661077\n",
      "  0.16849719 -0.31278843  0.06667123 -0.13669346  0.32461685  0.09295267\n",
      " -0.22703646  0.13133678  0.31731579 -0.11638959 -0.00421851  0.06002282\n",
      "  0.04536716 -0.34953755]\n",
      "200\n",
      "2\n",
      "(398925, 200)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print  type(wordlist)\n",
    "print len(wordlist)\n",
    "print json.dumps(wordlist[1:20],ensure_ascii=False).encode('utf-8')\n",
    "print '------------------------------------------------------------------------------------------------------'\n",
    "print  type(wordVector)\n",
    "print len(wordVector)\n",
    "print(wordVector[0])\n",
    "print len(wordVector[0])\n",
    "\n",
    "print(wordVector.ndim)\n",
    "print(wordVector.shape)\n",
    "print(wordVector.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n[Spectral Clustering \\xe5\\x89\\x8d\\xe8\\x99\\x95\\xe7\\x90\\x86]\\n\\nimport numpy as np\\n\\n\\xe5\\x85\\xa8\\xe9\\x83\\xa8\\xe8\\xa9\\x9e\\xe7\\xae\\x97\\xe7\\x9b\\xb8\\xe4\\xbc\\xbc\\xe5\\xba\\xa6\\n\\nsmatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(model.syn0.T))\\nnsarray = np.array(smatrix) <=== \\xe6\\x9c\\x83\\xe7\\x95\\xb6\\xe6\\xa9\\x9f\\n\\n\\xe8\\x8b\\xa5\\xe5\\xb7\\xb2\\xe7\\xb6\\x93\\xe6\\x8a\\x8a\\xe8\\xa9\\x9e\\xe7\\x9a\\x84\\xe7\\xaf\\x84\\xe5\\x9c\\x8d\\xe7\\xb8\\xae\\xe6\\xb8\\x9b\\xef\\xbc\\x8c\\xe5\\x89\\x87\\xe5\\x8f\\xaf\\xe7\\x94\\xa8\\xe4\\xb8\\x8b\\xe9\\x9d\\xa2\\xe9\\x80\\x99\\xe5\\x80\\x8b\\xe6\\x96\\xb9\\xe5\\xbc\\x8f\\n\\xe6\\xaf\\x8f\\xe5\\x80\\x8b\\xe8\\xa9\\x9e\\xe7\\x9a\\x84\\xe5\\x90\\x91\\xe9\\x87\\x8f\\xe9\\x95\\xb7\\xe5\\xba\\xa6\\xe6\\x98\\xafn\\xef\\xbc\\x8c\\xe8\\xa8\\x93\\xe7\\xb7\\xb4\\xe6\\x99\\x82\\xe6\\x88\\x91\\xe6\\x98\\xaf\\xe5\\xb0\\x87n\\xe8\\xa8\\xad\\xe7\\x82\\xba200\\n\\xe6\\x8e\\xa5\\xe8\\x91\\x97\\xe6\\x8a\\x8a\\xe8\\xa9\\x9e\\xe5\\x90\\x91\\xe9\\x87\\x8f\\xe6\\x94\\xbe\\xe5\\x85\\xa5list\\n\\nwordVectorList = [wordvector1,wordvector2,...,...]\\nnsmatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(np.array(wordVectorList).T))\\n\\n\\xe7\\xae\\x97\\xe5\\x87\\xba\\xe4\\xbe\\x86\\xe7\\x9a\\x84\\xe7\\x9b\\xb8\\xe4\\xbc\\xbc\\xe5\\xba\\xa6\\xe5\\x9b\\xa0\\xe7\\x82\\xba\\xe6\\x98\\xaf\\xe6\\xb5\\xae\\xe9\\xbb\\x9e\\xe6\\x95\\xb8\\xef\\xbc\\x8c\\xe6\\x9c\\x83\\xe6\\x9c\\x89>1\\xe6\\x88\\x96<-1\\xe7\\x9a\\x84\\xe6\\x83\\x85\\xe6\\xb3\\x81\\xef\\xbc\\x8c\\xe8\\xa6\\x81\\xe5\\x86\\x8d\\xe4\\xbf\\xae\\xe6\\xad\\xa3\\n\\nnsarray = np.array(nsmatrix)\\nnsarray[nsarray>1] = 1.0\\nnsarray[nsarray<-1] = -1.0\\n\\n\\xe5\\x8f\\xa6\\xe5\\xa4\\x96\\xe5\\x8f\\xaf\\xe4\\xbb\\xa5\\xe6\\x8a\\x8a\\xe9\\xa4\\x98\\xe5\\xbc\\xa6\\xe7\\x9b\\xb8\\xe4\\xbc\\xbc\\xe5\\xba\\xa6\\xe8\\xbd\\x89\\xe6\\x8f\\x9b\\xe7\\x82\\xba\\xe5\\xbc\\xa7\\xe5\\xba\\xa6\\xef\\xbc\\x8c\\xe5\\x86\\x8d\\xe8\\xbd\\x89\\xe6\\x8f\\x9b\\xe7\\x82\\xba\\xe4\\xbb\\x8b\\xe6\\x96\\xbc0~1\\xe4\\xb9\\x8b\\xe9\\x96\\x93\\xe7\\x9a\\x84\\xe7\\x9b\\xb8\\xe4\\xbc\\xbc\\xe5\\xba\\xa6\\n\\nangularD = np.arccos(nsarray)/math.pi\\nsim = 1 - angularD\\n\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "[Spectral Clustering 前處理]\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "全部詞算相似度\n",
    "\n",
    "smatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(model.syn0.T))\n",
    "nsarray = np.array(smatrix) <=== 會當機\n",
    "\n",
    "若已經把詞的範圍縮減，則可用下面這個方式\n",
    "每個詞的向量長度是n，訓練時我是將n設為200\n",
    "接著把詞向量放入list\n",
    "\n",
    "wordVectorList = [wordvector1,wordvector2,...,...]\n",
    "nsmatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(np.array(wordVectorList).T))\n",
    "\n",
    "算出來的相似度因為是浮點數，會有>1或<-1的情況，要再修正\n",
    "smatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(model.syn0.T))\n",
    "nsarray = np.array(smatrix) smatrix = gensim.similarities.MatrixSimilarity(gensim.matutils.Dense2Corpus(model.syn0.T))\n",
    "nsarray = np.array(smatrix) \n",
    "nsarray = np.array(nsmatrix)\n",
    "nsarray[nsarray>1] = 1.0\n",
    "nsarray[nsarray<-1] = -1.0\n",
    "\n",
    "另外可以把餘弦相似度轉換為弧度，再轉換為介於0~1之間的相似度\n",
    "\n",
    "angularD = np.arccos(nsarray)/math.pi\n",
    "sim = 1 - angularD\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-74747816a7cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m# computing K-Means with K = 2 (2 clusters)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mcentroids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;31m# assign each sample to a cluster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcentroids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/scipy/cluster/vq.pyc\u001b[0m in \u001b[0;36mkmeans\u001b[1;34m(obs, k_or_guess, iter, thresh, check_finite)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    538\u001b[0m     \"\"\"\n\u001b[1;32m--> 539\u001b[1;33m     \u001b[0mobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_validated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_finite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    540\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'iter must be at least 1.'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/scipy/_lib/_util.pyc\u001b[0m in \u001b[0;36m_asarray_validated\u001b[1;34m(a, check_finite, sparse_ok, objects_ok, mask_ok, as_inexact)\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'masked arrays are not supported'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[0mtoarray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray_chkfinite\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcheck_finite\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mobjects_ok\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'O'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36masarray_chkfinite\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    664\u001b[0m     \"\"\"\n\u001b[0;32m    665\u001b[0m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 666\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtypecodes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'AllFloat'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    667\u001b[0m         raise ValueError(\n\u001b[0;32m    668\u001b[0m             \"array must not contain infs or NaNs\")\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken for K Means clustering:  1711.21886206 seconds.\n",
      "\n",
      "Cluster 0\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 1120, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 301, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.py\", line 346, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"/home/dondon/App/Anaconda2/lib/python2.7/inspect.py\", line 491, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[0;32m   1828\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 1830\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   1831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1393\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1394\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1395\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1300\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1302\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1303\u001b[0m             )\n\u001b[0;32m   1304\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/dondon/App/Anaconda2/lib/python2.7/site-packages/IPython/core/ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1184\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "\n",
    "\n",
    "word_vectors = model.syn0\n",
    "num_clusters =15\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\"\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))\n",
    "\n",
    "# For the first 10 clusters\n",
    "for cluster in xrange(0,10):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
