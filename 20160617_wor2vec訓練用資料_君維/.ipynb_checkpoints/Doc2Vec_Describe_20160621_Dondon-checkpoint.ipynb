{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging\n",
    "import json\n",
    "\n",
    "model = gensim.models.Doc2Vec.load('./data/Doc2Vec_Size_100_1_m_new')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "魯肉飯 0.921170175076\n",
      "肉燥飯 0.860764622688\n",
      "控肉飯 0.824838399887\n",
      "麵線 0.808075010777\n",
      "雞肉飯 0.807068169117\n",
      "乾麵 0.798507988453\n",
      "豬油拌飯 0.788621544838\n",
      "油飯 0.769047021866\n",
      "肉羹湯 0.761376202106\n",
      "排骨飯 0.760819017887\n"
     ]
    }
   ],
   "source": [
    "# 相似度\n",
    "for ele in model.most_similar(u'滷肉飯', topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56079d212756dd184f282124 0.756299734116\n",
      "56cb0ade699b6e0737c94c6b 0.756243050098\n",
      "54c4a1d62756dd7ce9f38d3d 0.733508527279\n",
      "54a172bcd4fdab219233e7fe 0.711138725281\n",
      "53bdcbdfd4fdab09ca3909e3 0.709210634232\n"
     ]
    }
   ],
   "source": [
    "#作者相似度\n",
    "for ele in model.docvecs.most_similar([\"557bca87699b6e6e88553d8e\"], topn = 5):\n",
    "        print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蔬菜水果 0.579964160919\n",
      "魚料 0.553462982178\n",
      "生菜 0.549664080143\n",
      "肉類 0.54927700758\n",
      "肉品 0.538128256798\n",
      "肉片 0.533275485039\n",
      "魚生 0.533119559288\n",
      "蔬果 0.531435668468\n",
      "生魚片 0.522937238216\n",
      "食材 0.516968011856\n"
     ]
    }
   ],
   "source": [
    "for ele in model.most_similar(positive=[u'蔬菜'], negative=[u'菇'], topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "雞排 0.630074322224\n",
      "Pizza 0.616584599018\n",
      "熱狗堡 0.615270376205\n",
      "豬排 0.606273591518\n",
      "潛艇堡 0.606119453907\n",
      "甜甜圈 0.593104064465\n",
      "雞腿堡 0.589587569237\n",
      "鬆餅 0.58511865139\n",
      "美式漢堡 0.583975553513\n",
      "牛排 0.578551292419\n"
     ]
    }
   ],
   "source": [
    "for ele in model.most_similar(positive=[u'炸雞',u'漢堡'], negative=[u'青菜'], topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "蔬果 0.86394816637\n",
      "菇類 0.857580423355\n",
      "青菜 0.821973264217\n",
      "蔬菜水果 0.782311081886\n",
      "各式蔬菜 0.77644443512\n",
      "生菜 0.774259567261\n",
      "蔬菜類 0.729254841805\n",
      "海鮮 0.724322378635\n",
      "青蔬 0.722296774387\n",
      "鮮蔬 0.719903290272\n"
     ]
    }
   ],
   "source": [
    "for ele in model.most_similar([u'蔬菜'],topn=10):\n",
    "    print ele[0], ele[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "583282\n",
      "291\n"
     ]
    }
   ],
   "source": [
    "# KMean前處理\n",
    "# 詞清單\n",
    "wordlist = model.index2word\n",
    "# 詞向量\n",
    "wordVector = model.syn0\n",
    "wordVectorShape=wordVector.shape[0]\n",
    "print  wordVectorShape\n",
    "num_clusters = wordVectorShape/ 2000\n",
    "print num_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wordList\n",
      "<type 'list'>\n",
      "583282\n",
      "[\"是\", \"了\", \"有\", \"也\", \"吃\", \"我\", \"很\", \"在\", \"就\", \"都\", \"這\", \"可以\", \"還\", \"人\", \"好\", \"會\", \"不\", \"到\", \"但\"]\n",
      "------------------------------------------------------------------------------------------------------\n",
      "wordVector\n",
      "<type 'numpy.ndarray'>\n",
      "583282\n",
      "[ 0.06837536 -0.05807261  0.0389644  -0.15750736  0.15592451  0.20105292\n",
      " -0.24923302 -0.1437584   0.42875957  0.26418081  0.00195585  0.11227558\n",
      "  0.3217729  -0.01073016  0.33973065  0.0448878   0.14028962 -0.03044422\n",
      "  0.22284797  0.08576545 -0.05249853 -0.29188132 -0.14343002  0.25153458\n",
      "  0.31376445  0.2476249  -0.18230712  0.01990437 -0.21710335  0.35208499\n",
      " -0.0865749  -0.31514111 -0.33335286  0.23762192 -0.01303413 -0.05992471\n",
      "  0.01800369  0.45280284  0.01626151  0.19404696  0.37893733  0.32992086\n",
      "  0.17666526  0.57595092  0.1573413   0.15635191  0.19357808  0.23966353\n",
      " -0.06166536  0.29923305 -0.18488461 -0.0261014   0.1580822  -0.15366933\n",
      " -0.04145152  0.01318101 -0.03228415  0.25477117 -0.04354706 -0.02408406\n",
      "  0.08103221 -0.39208686  0.09379543 -0.08351466 -0.10179646 -0.0362829\n",
      "  0.08973779  0.11136728  0.01561181 -0.14443032 -0.38153854  0.03822418\n",
      "  0.31649849  0.16694409 -0.48981234  0.25465047  0.04283802 -0.01513083\n",
      " -0.15433881 -0.09452193 -0.08481815 -0.12285227  0.13813618  0.0753443\n",
      "  0.06888887 -0.13217057  0.17235363  0.27375165 -0.1477107   0.0092601\n",
      " -0.01676381 -0.12583871 -0.00728162 -0.12663364  0.28127599  0.2899107\n",
      " -0.19651058  0.14582889 -0.01355646  0.29728383]\n",
      "100\n",
      "2\n",
      "(583282, 100)\n",
      "float32\n"
     ]
    }
   ],
   "source": [
    "print 'wordList:'\n",
    "print  type(wordlist)\n",
    "print len(wordlist)\n",
    "print json.dumps(wordlist[1:20],ensure_ascii=False).encode('utf-8')\n",
    "print '------------------------------------------------------------------------------------------------------'\n",
    "print 'wordVector'\n",
    "print  type(wordVector)\n",
    "print len(wordVector)\n",
    "print(wordVector[0])\n",
    "print len(wordVector[0])\n",
    "\n",
    "print(wordVector.ndim)\n",
    "print(wordVector.shape)\n",
    "print(wordVector.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import time\n",
    "\n",
    "start = time.time() # Start time\n",
    "\n",
    "# Set \"k\" (num_clusters) to be 1/5th of the vocabulary size, or an\n",
    "# average of 5 words per cluster\n",
    "\n",
    "\n",
    "word_vectors = model.syn0\n",
    "#num_clusters = 200\n",
    "num_clusters = wordVectorShape/ 2000\n",
    "\n",
    "# Initalize a k-means object and use it to extract centroids\n",
    "kmeans_clustering = KMeans( n_clusters = num_clusters )\n",
    "idx = kmeans_clustering.fit_predict( word_vectors )\n",
    "\n",
    "# Get the end time and print how long the process took\n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print \"Time taken for K Means clustering: \", elapsed, \"seconds.\"\n",
    "\n",
    "# Create a Word / Index dictionary, mapping each vocabulary word to\n",
    "# a cluster number                                                                                            \n",
    "word_centroid_map = dict(zip( model.index2word, idx ))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the first 10 clusters\n",
    "for cluster in xrange(0,10):\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])\n",
    "    print words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./data/doc2Vec_KMeans200.json','w') as f:\n",
    "    json.dump(word_centroid_map,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "stratTime=time.time()\n",
    "for cluster in xrange(0,2):\n",
    "    #\n",
    "    # Print the cluster number  \n",
    "    print \"\\nCluster %d\" % cluster\n",
    "    #l.syn0\n",
    "    # Find all of the words for that cluster number, and print them out\n",
    "    words = []\n",
    "    for i in xrange(0,len(word_centroid_map.values())):\n",
    "        if( word_centroid_map.values()[i] == cluster ):\n",
    "            words.append(word_centroid_map.keys()[i])    \n",
    "    print json.dumps(words,ensure_ascii=False).encode('utf-8') \n",
    "EndTime = time.time()\n",
    "CostTime = EndTime - stratTime\n",
    "print '總共花了',CostTime,'秒'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
